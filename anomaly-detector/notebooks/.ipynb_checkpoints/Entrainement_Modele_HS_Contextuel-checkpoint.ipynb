{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a79defa-e335-4bc0-aae5-c7e5b8cf675e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librairies importées avec succès.\n"
     ]
    }
   ],
   "source": [
    "# Cellule 1: Imports et Configuration\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "\n",
    "# Ignorer les avertissements futurs pour garder une sortie propre\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "print(\"Librairies importées avec succès.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cc7e848-7775-41e0-8a9b-0f3a9e0a69b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Génération du jeu de données d'entraînement synthétique...\n",
      "-> Dataset de 1000 lignes créé et sauvegardé dans './models/dataset_hs_contextuel.csv'\n",
      "\n",
      "Aperçu des 5 premières lignes du dataset :\n",
      "   hs_minutes  taux_absence_service  nb_hs_validees_historique  \\\n",
      "0          89              0.361278                         24   \n",
      "1         100              0.447711                          9   \n",
      "2         136              0.117052                          0   \n",
      "3          97              0.123559                          3   \n",
      "4         230              0.229517                         10   \n",
      "\n",
      "   decision_reelle  \n",
      "0                1  \n",
      "1                1  \n",
      "2                0  \n",
      "3                0  \n",
      "4                0  \n"
     ]
    }
   ],
   "source": [
    "# Cellule 2: Génération du Dataset Synthétique (Version Corrigée)\n",
    "\n",
    "print(\"Génération du jeu de données d'entraînement synthétique...\")\n",
    "\n",
    "# ... (toute la partie génération de données reste la même) ...\n",
    "n_exemples = 1000\n",
    "data = []\n",
    "for _ in range(n_exemples):\n",
    "    hs_minutes = np.random.randint(10, 240)\n",
    "    taux_absence = np.random.rand() * 0.6\n",
    "    historique_hs = np.random.randint(0, 25)\n",
    "    score = 0\n",
    "    if taux_absence > 0.4: score += 2\n",
    "    if historique_hs > 10: score += 2\n",
    "    if hs_minutes > 180: score -= 2\n",
    "    if hs_minutes < 30: score += 1\n",
    "    decision_reelle = 1 if score >= 2 else 0\n",
    "    data.append([hs_minutes, taux_absence, historique_hs, decision_reelle])\n",
    "columns = ['hs_minutes', 'taux_absence_service', 'nb_hs_validees_historique', 'decision_reelle']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# --- CORRECTION DU CHEMIN DE SAUVEGARDE ---\n",
    "# S'assurer que le dossier 'models' existe\n",
    "if not os.path.exists('./models'):\n",
    "    os.makedirs('./models')\n",
    "\n",
    "# Sauvegarder le dataset DANS le dossier 'models'\n",
    "dataset_path = './models/dataset_hs_contextuel.csv' # <-- CHEMIN CORRIGÉ\n",
    "df.to_csv(dataset_path, index=False)\n",
    "\n",
    "print(f\"-> Dataset de {len(df)} lignes créé et sauvegardé dans '{dataset_path}'\")\n",
    "print(\"\\nAperçu des 5 premières lignes du dataset :\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b35906b5-5f1f-41d6-8abc-cc72fcb19c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Début du processus d'entraînement...\n",
      "Données divisées : 800 pour l'entraînement, 200 pour le test.\n",
      "\n",
      "Entraînement du modèle...\n",
      "[LightGBM] [Info] Number of positive: 439, number of negative: 361\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 444\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.548750 -> initscore=0.195621\n",
      "[LightGBM] [Info] Start training from score 0.195621\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "-> Modèle entraîné.\n",
      "\n",
      "Précision du modèle sur le set de test : 100.00%\n",
      "\n",
      "Rapport de classification détaillé :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " REJETER (0)       1.00      1.00      1.00        90\n",
      "ACCEPTER (1)       1.00      1.00      1.00       110\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n",
      "\n",
      "--- SUCCÈS ---\n",
      "Le modèle entraîné a été sauvegardé ici : './models/model_hs_contextuel.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Cellule 3: Entraînement et Sauvegarde du Modèle (Version Corrigée)\n",
    "\n",
    "print(\"\\nDébut du processus d'entraînement...\")\n",
    "\n",
    "# --- CORRECTION DU CHEMIN DE LECTURE ---\n",
    "# Définir le chemin vers le dataset que nous venons de créer\n",
    "dataset_path = './models/dataset_hs_contextuel.csv' # <-- CHEMIN CORRIGÉ\n",
    "\n",
    "# 1. Charger le dataset\n",
    "df_train = pd.read_csv(dataset_path)\n",
    "\n",
    "# 2. Séparer les 'features' et la 'target'\n",
    "X = df_train.drop('decision_reelle', axis=1)\n",
    "y = df_train['decision_reelle']\n",
    "\n",
    "# 3. Diviser les données pour l'entraînement et pour le test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Données divisées : {len(X_train)} pour l'entraînement, {len(X_test)} pour le test.\")\n",
    "\n",
    "# 4. Créer et entraîner le modèle\n",
    "print(\"\\nEntraînement du modèle...\")\n",
    "model = lgb.LGBMClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"-> Modèle entraîné.\")\n",
    "\n",
    "# 5. Évaluer la performance\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nPrécision du modèle sur le set de test : {accuracy:.2%}\")\n",
    "print(\"\\nRapport de classification détaillé :\")\n",
    "print(classification_report(y_test, y_pred, target_names=['REJETER (0)', 'ACCEPTER (1)']))\n",
    "\n",
    "# 6. Sauvegarder le modèle entraîné (le \"cerveau\") dans le dossier 'models'\n",
    "model_path = './models/model_hs_contextuel.pkl'\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "print(f\"\\n--- SUCCÈS ---\")\n",
    "print(f\"Le modèle entraîné a été sauvegardé ici : '{model_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde42ecb-b6d6-4bac-b61b-45b89ed87ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed839c4c-54c8-48d1-b92f-0daccfedff66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
