{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efa66276-5cab-4c08-8748-75bcb30904ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib # ou pickle\n",
    "\n",
    "# --- BLOC DE CONFIGURATION DES CHEMINS (À METTRE AU DÉBUT) ---\n",
    "\n",
    "# Le chemin vers le dossier 'models' est UN NIVEAU AU-DESSUS (../) du dossier 'notebooks'\n",
    "MODELS_DIR = '../models'\n",
    "\n",
    "# On s'assure que ce dossier existe. S'il n'existe pas, on le crée.\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.makedirs(MODELS_DIR)\n",
    "\n",
    "# -----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d071167-4eb6-4792-80c2-fd9c1b55db09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ÉTAPE 1: Connexion BDD ---\n",
      "Connexion réussie.\n",
      "\n",
      "--- ÉTAPE 2: Chargement et nettoyage ---\n",
      "6 absences/congés valides chargés.\n",
      "\n",
      "--- ÉTAPE 3: Génération du dataset d'entraînement ---\n",
      "Dataset généré avec 6 lignes.\n",
      "\n",
      "--- ÉTAPE 3.5: Vérification et duplication des classes rares ---\n",
      "Distribution des décisions AVANT duplication:\n",
      " decision_absence\n",
      "DECOMPTE_SOLDE         4\n",
      "JUSTIFICATIF_REQUIS    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution des décisions APRÈS duplication:\n",
      " decision_absence\n",
      "DECOMPTE_SOLDE         4\n",
      "JUSTIFICATIF_REQUIS    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- ÉTAPE 4: Entraînement du modèle ---\n",
      "Dataset de 6 échantillons. Séparation en Test (2) et Entraînement.\n",
      "Nombre de classes détectées : 2\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 4, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score -0.287682\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Entraînement du modèle terminé.\n",
      "\n",
      "Évaluation du modèle...\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "     DECOMPTE_SOLDE       0.50      1.00      0.67         1\n",
      "JUSTIFICATIF_REQUIS       0.00      0.00      0.00         1\n",
      "\n",
      "           accuracy                           0.50         2\n",
      "          macro avg       0.25      0.50      0.33         2\n",
      "       weighted avg       0.25      0.50      0.33         2\n",
      "\n",
      "\n",
      "--- ÉTAPE 5: Sauvegarde ---\n",
      "Modèle sauvegardé dans : ../models\\model_absence_injustifiee.pkl\n",
      "Encodeur de décision sauvegardé dans : ../models\\encoder_decision_absence.pkl\n",
      "\n",
      "Processus terminé.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# NOTEBOOK FINAL ET UNIQUE (Version 4 - Anti-Crash)\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# --- ÉTAPE 1: CONNEXION BDD ---\n",
    "print(\"--- ÉTAPE 1: Connexion BDD ---\")\n",
    "db_user, db_password, db_host, db_port, db_name = 'root', 'root', 'localhost', '3306', 'sicda_easytime'\n",
    "engine = create_engine(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\")\n",
    "print(\"Connexion réussie.\")\n",
    "\n",
    "# --- ÉTAPE 2: CHARGEMENT ET NETTOYAGE ---\n",
    "print(\"\\n--- ÉTAPE 2: Chargement et nettoyage ---\")\n",
    "df_absences = pd.read_sql(\"\"\"\n",
    "    SELECT USER_FK as employe_id, DATE_DEBUT as date_debut, DATE_REPRISE as date_fin \n",
    "    FROM absence WHERE STATUT = 'workflow_status_validated'\n",
    "    UNION ALL\n",
    "    SELECT USER_FK as employe_id, DATE_DEBUT as date_debut, DATE_REPRISE as date_fin \n",
    "    FROM conge WHERE STATUT = 'workflow_status_validated'\n",
    "\"\"\", engine)\n",
    "df_employes = pd.read_sql(\"SELECT ID as employe_id, SOLDE_ANNUEL as solde_conges_jours FROM utilisateur\", engine)\n",
    "\n",
    "df_absences['date_debut'] = pd.to_datetime(df_absences['date_debut'], errors='coerce')\n",
    "df_absences['date_fin'] = pd.to_datetime(df_absences['date_fin'], errors='coerce')\n",
    "df_absences.dropna(subset=['date_debut', 'date_fin'], inplace=True)\n",
    "df_absences['duree_absence_jours'] = (df_absences['date_fin'] - df_absences['date_debut']).dt.days + 1\n",
    "print(f\"{len(df_absences)} absences/congés valides chargés.\")\n",
    "\n",
    "# --- ÉTAPE 3: GÉNÉRATION DU DATASET ---\n",
    "print(\"\\n--- ÉTAPE 3: Génération du dataset d'entraînement ---\")\n",
    "dataset_rows = []\n",
    "decisions = ['DECOMPTE_SOLDE', 'JUSTIFICATIF_REQUIS', 'AVERTISSEMENT']\n",
    "\n",
    "for _, absence in df_absences.iterrows():\n",
    "    employe_id = absence['employe_id']\n",
    "    solde_info = df_employes[df_employes['employe_id'] == employe_id]\n",
    "    solde_conges = solde_info['solde_conges_jours'].iloc[0] if not solde_info.empty else 0\n",
    "    \n",
    "    decision = np.random.choice(decisions, p=[0.6, 0.3, 0.1])\n",
    "    if solde_conges is not None and solde_conges <= 1:\n",
    "        decision = np.random.choice(['JUSTIFICATIF_REQUIS', 'AVERTISSEMENT'], p=[0.5, 0.5])\n",
    "    \n",
    "    dataset_rows.append({\n",
    "        'duree_absence_jours': absence['duree_absence_jours'],\n",
    "        'solde_conges_jours': solde_conges if solde_conges is not None else 0,\n",
    "        'nb_absences_injustifiees_annee': np.random.randint(0, 5),\n",
    "        'est_adjacent_weekend_ferie': 1 if absence['date_debut'].weekday() in [0, 4] else 0,\n",
    "        'charge_equipe': round(np.random.uniform(0.4, 1.0), 2),\n",
    "        'decision_absence': decision\n",
    "    })\n",
    "\n",
    "df_final = pd.DataFrame(dataset_rows)\n",
    "print(f\"Dataset généré avec {len(df_final)} lignes.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# NOUVELLE ÉTAPE DE SÉCURITÉ : GARANTIR AU MOINS 2 EXEMPLES PAR CLASSE\n",
    "# ==============================================================================\n",
    "print(\"\\n--- ÉTAPE 3.5: Vérification et duplication des classes rares ---\")\n",
    "class_counts = df_final['decision_absence'].value_counts()\n",
    "print(\"Distribution des décisions AVANT duplication:\\n\", class_counts)\n",
    "\n",
    "# On identifie les classes avec un seul exemple\n",
    "classes_rares = class_counts[class_counts < 2].index\n",
    "\n",
    "for classe in classes_rares:\n",
    "    # On trouve la ligne de cette classe rare\n",
    "    ligne_a_dupliquer = df_final[df_final['decision_absence'] == classe]\n",
    "    # On l'ajoute à nouveau au DataFrame\n",
    "    df_final = pd.concat([df_final, ligne_a_dupliquer], ignore_index=True)\n",
    "    print(f\"La classe '{classe}' a été dupliquée pour éviter une erreur.\")\n",
    "\n",
    "print(\"\\nDistribution des décisions APRÈS duplication:\\n\", df_final['decision_absence'].value_counts())\n",
    "# ==============================================================================\n",
    "\n",
    "# ==============================================================================\n",
    "# --- ÉTAPE 4: ENTRAÎNEMENT DU MODÈLE (Version Robuste) ---\n",
    "# ==============================================================================\n",
    "print(\"\\n--- ÉTAPE 4: Entraînement du modèle ---\")\n",
    "\n",
    "# --- 4.1 Préparation des données pour le modèle ---\n",
    "encoder_decision_absence = LabelEncoder()\n",
    "df_final['decision_absence_encoded'] = encoder_decision_absence.fit_transform(df_final['decision_absence'])\n",
    "\n",
    "features = ['duree_absence_jours', 'solde_conges_jours', 'nb_absences_injustifiees_annee', 'est_adjacent_weekend_ferie', 'charge_equipe']\n",
    "target = 'decision_absence_encoded'\n",
    "X = df_final[features]\n",
    "y = df_final[target]\n",
    "\n",
    "# --- 4.2 Séparation dynamique et sécurisée des données ---\n",
    "num_classes = len(y.unique())\n",
    "n_samples = len(X)\n",
    "\n",
    "# On s'assure que la taille du test est au minimum le nombre de classes pour permettre la stratification\n",
    "final_test_size = max(int(n_samples * 0.2), num_classes)\n",
    "\n",
    "if n_samples > final_test_size:\n",
    "    print(f\"Dataset de {n_samples} échantillons. Séparation en Test ({final_test_size}) et Entraînement.\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=final_test_size, random_state=42, stratify=y\n",
    "    )\n",
    "else:\n",
    "    print(f\"ATTENTION: Pas assez de données ({n_samples}) pour créer un ensemble de test valide. Tout sera utilisé pour l'entraînement.\")\n",
    "    X_train, y_train = X, y\n",
    "    X_test, y_test = pd.DataFrame(columns=X.columns), pd.Series(dtype=y.dtype) # Créer des dataframes vides pour la suite\n",
    "\n",
    "# --- 4.3 Entraînement du modèle ---\n",
    "print(f\"Nombre de classes détectées : {num_classes}\")\n",
    "lgbm_classifier = lgb.LGBMClassifier(objective='multiclass', num_class=num_classes, random_state=42)\n",
    "lgbm_classifier.fit(X_train, y_train)\n",
    "print(\"Entraînement du modèle terminé.\")\n",
    "\n",
    "# --- 4.4 Évaluation du modèle (seulement si on a un ensemble de test) ---\n",
    "if not X_test.empty:\n",
    "    print(\"\\nÉvaluation du modèle...\")\n",
    "    y_pred = lgbm_classifier.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, target_names=encoder_decision_absence.classes_, zero_division=0))\n",
    "else:\n",
    "    print(\"\\nPas d'évaluation possible car il n'y a pas d'ensemble de test.\")\n",
    "\n",
    "# --- ÉTAPE 5: SAUVEGARDE ---\n",
    "print(\"\\n--- ÉTAPE 5: Sauvegarde ---\")\n",
    "\n",
    "model_path = os.path.join(MODELS_DIR, 'model_absence_injustifiee.pkl')\n",
    "joblib.dump(lgbm_classifier, model_path)\n",
    "print(f\"Modèle sauvegardé dans : {model_path}\")\n",
    "encoder_path = os.path.join(MODELS_DIR, 'encoder_decision_absence.pkl')\n",
    "joblib.dump(encoder_decision_absence, encoder_path)\n",
    "print(f\"Encodeur de décision sauvegardé dans : {encoder_path}\")\n",
    "    \n",
    "print(\"\\nProcessus terminé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0443e1e2-d035-4eaa-9ae5-a4eb6de8f66e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
