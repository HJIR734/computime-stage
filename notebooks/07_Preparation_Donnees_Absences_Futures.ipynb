{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80a6ca00-870d-4004-8363-4238f68aadb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timedelta in c:\\users\\hjirt\\anaconda1\\lib\\site-packages (2020.12.3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "187d4200-6c61-4383-afc4-ccf18334f945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connexion BDD prête.\n",
      "\n",
      "--- Chargement des données brutes ---\n",
      "Données chargées.\n",
      "\n",
      "--- Préparation et nettoyage ---\n",
      "Données préparées.\n",
      "\n",
      "--- Génération du dataset jour par jour ---\n",
      "Génération des données entre 2016-09-12 et 2025-08-07...\n",
      "Dataset brut généré avec 24691 lignes.\n",
      "\n",
      "--- Création du DataFrame final ---\n",
      "Dataset final sauvegardé dans 'data/dataset_absences.csv'.\n",
      "\n",
      "Analyse de la Cible:\n",
      "est_absent\n",
      "0    0.999263\n",
      "1    0.000737\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# NOTEBOOK 1 FINAL (Version 2) : GÉNÉRATION D'UN DATASET COMPLET\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "\n",
    "# --- 1. CONNEXION (inchangé) ---\n",
    "db_user, db_password, db_host, db_port, db_name = 'root', 'root', 'localhost', '3306', 'sicda_easytime'\n",
    "engine = create_engine(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\")\n",
    "print(\"Connexion BDD prête.\")\n",
    "\n",
    "# --- 2. CHARGEMENT (inchangé) ---\n",
    "print(\"\\n--- Chargement des données brutes ---\")\n",
    "df_absences = pd.read_sql(\"SELECT USER_FK as employe_id, DATE_DEBUT as date_debut, DATE_REPRISE as date_fin FROM absence WHERE STATUT = 'workflow_status_validated'\", engine)\n",
    "df_conges = pd.read_sql(\"SELECT USER_FK as employe_id, DATE_DEBUT as date_debut, DATE_REPRISE as date_fin FROM conge WHERE STATUT = 'workflow_status_validated'\", engine)\n",
    "df_employes = pd.read_sql(\"SELECT ID as employe_id, DATE_EMB as date_embauche, PROFIL_METIER_FK as profil_metier_id, NOEUD_FK as noeud_id FROM utilisateur\", engine)\n",
    "df_feries = pd.read_sql(\"SELECT DATE_DEBUT as date FROM jr_ferie\", engine)\n",
    "print(\"Données chargées.\")\n",
    "\n",
    "# --- 3. PRÉPARATION (inchangé) ---\n",
    "print(\"\\n--- Préparation et nettoyage ---\")\n",
    "for df in [df_absences, df_conges, df_feries, df_employes]:\n",
    "    for col in df.columns:\n",
    "        if 'date' in col: df[col] = pd.to_datetime(df[col], errors='coerce').dt.date\n",
    "\n",
    "feries_set = set(df_feries['date'].dropna())\n",
    "absences_dict = {}\n",
    "all_absences = pd.concat([df_absences, df_conges])\n",
    "for _, row in all_absences.iterrows():\n",
    "    if row['employe_id'] not in absences_dict: absences_dict[row['employe_id']] = []\n",
    "    absences_dict[row['employe_id']].append((row['date_debut'], row['date_fin']))\n",
    "print(\"Données préparées.\")\n",
    "\n",
    "# --- 4. GÉNÉRATION DU DATASET (inchangé, mais propre) ---\n",
    "print(\"\\n--- Génération du dataset jour par jour ---\")\n",
    "start_date = date(2016, 9, 12)\n",
    "end_date = date.today()\n",
    "date_range = pd.date_range(start_date, end_date)\n",
    "dataset_rows = []\n",
    "print(f\"Génération des données entre {start_date} et {end_date}...\")\n",
    "\n",
    "for _, employe in df_employes.iterrows():\n",
    "    if pd.isnull(employe['date_embauche']): continue\n",
    "    for single_date_dt in date_range:\n",
    "        single_date = single_date_dt.date()\n",
    "        if single_date < employe['date_embauche']: continue\n",
    "        \n",
    "        est_absent = 0\n",
    "        if employe['employe_id'] in absences_dict:\n",
    "            for debut, fin in absences_dict[employe['employe_id']]:\n",
    "                if debut and fin and debut <= single_date <= fin:\n",
    "                    est_absent = 1\n",
    "                    break\n",
    "        \n",
    "        dataset_rows.append({\n",
    "            'employe_id': employe['employe_id'], 'date': single_date,\n",
    "            'jour_semaine': single_date.weekday(), 'jour_mois': single_date.day, 'mois': single_date.month,\n",
    "            'semaine_annee': single_date.isocalendar()[1], 'profil_metier_id': employe['profil_metier_id'],\n",
    "            'noeud_id': employe['noeud_id'], 'est_ferie': 1 if single_date in feries_set else 0,\n",
    "            'veille_ferie': 1 if (single_date + timedelta(days=1)) in feries_set else 0,\n",
    "            'lendemain_ferie': 1 if (single_date - timedelta(days=1)) in feries_set else 0,\n",
    "            'est_absent': est_absent\n",
    "        })\n",
    "\n",
    "print(f\"Dataset brut généré avec {len(dataset_rows)} lignes.\")\n",
    "\n",
    "# --- 5. FINALISATION (inchangé) ---\n",
    "print(\"\\n--- Création du DataFrame final ---\")\n",
    "final_dataset = pd.DataFrame(dataset_rows)\n",
    "final_dataset = final_dataset[final_dataset['jour_semaine'] < 5]\n",
    "final_dataset.fillna(0, inplace=True)\n",
    "output_path = 'data/dataset_absences.csv'\n",
    "final_dataset.to_csv(output_path, index=False)\n",
    "print(f\"Dataset final sauvegardé dans '{output_path}'.\")\n",
    "print(\"\\nAnalyse de la Cible:\")\n",
    "print(final_dataset['est_absent'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee3f55f-5a34-496c-bd1c-93316749a13e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
